-sオプションと新しい-fオプションのどちらか一方を選択して使用できるようにしました。

Bash

#!/bin/bash

#================================================================
# CSVフィルタリングツール (TOP/END, リストファイル対応版)
#
# 説明:
#   指定された列の値が、指定された文字列(またはリストファイル)のいずれかと
#   一致するデータ行を抽出します。
#   ファイルの先頭にあるTOPレコードと末尾にあるENDレコードを自動的に処理し、
#   抽出後のデータに合わせて1列目のカウンタを再附番し、ENDレコードの
#   総レコード数を更新します。
#
# 入力CSVの前提フォーマット:
#   "0","TOP",...
#   "1","DATA",...
#   ...
#   "N","END","N+1"
#
# 使用方法:
#   ./filter_csv.sh -c <列番号> {-s <文字列> | -f <リストファイル>} [file1.csv ...]
#
# オプション:
#   -c <列番号>        : フィルタリング対象のカラム番号。必須。
#   -s <文字列>        : 抽出する文字列をカンマ区切りで指定 (例: "G111,G3333")。
#   -f <リストファイル> : 抽出する文字列を1行1件で記述したファイル。
#   -h                 : このヘルプメッセージを表示する。
#
# 使用例:
#   # 3列目が "A01" または "B02" の行を抽出
#   ./filter_csv.sh -c 3 -s "A01,B02" data.csv
#
#   # list.txtに記載されたIDで3列目を抽出
#   ./filter_csv.sh -c 3 -f list.txt data.csv
#
#================================================================

# --- デフォルト設定 ---
COLUMN=""
MATCH_STRINGS=""
LIST_FILE=""

# --- ヘルプメッセージ表示関数 ---
usage() {
    echo "使用方法: $0 -c <列番号> {-s <文字列> | -f <リストファイル>} [file1.csv ...]"
    echo "  -c <列番号>        : フィルタリング対象のカラム番号。必須。"
    echo "  -s <文字列>        : 抽出する文字列をカンマ区切りで指定 (例: \"G111,G3333\")。"
    echo "  -f <リストファイル> : 抽出する文字列を1行1件で記述したファイル。"
    echo "  -h                 : このヘルプメッセージを表示する。"
    exit 1
}

# --- オプション解析 ---
while getopts "c:s:f:h" opt; do
    case ${opt} in
        c)
            COLUMN=${OPTARG}
            ;;
        s)
            MATCH_STRINGS=${OPTARG}
            ;;
        f)
            LIST_FILE=${OPTARG}
            ;;
        h)
            usage
            ;;
        \?)
            usage
            ;;
    esac
done
shift $((OPTIND - 1))

# --- 必須引数の検証 ---
if [ -z "${COLUMN}" ]; then
    echo "エラー: -c は必須オプションです。" >&2
    usage
fi

if [ -n "${MATCH_STRINGS}" ] && [ -n "${LIST_FILE}" ]; then
    echo "エラー: -s と -f オプションは同時に指定できません。" >&2
    usage
fi

if [ -z "${MATCH_STRINGS}" ] && [ -z "${LIST_FILE}" ]; then
    echo "エラー: -s または -f のどちらか一方を指定してください。" >&2
    usage
fi

if [ -n "${LIST_FILE}" ] && [ ! -f "${LIST_FILE}" ]; then
    echo "エラー: リストファイルが見つかりません: ${LIST_FILE}" >&2
    exit 1
fi

if [ $# -eq 0 ]; then
    echo "エラー: 処理対象のファイルが指定されていません。" >&2
    usage
fi

# --- メイン処理ループ ---
for file in "$@"; do
    if [ ! -f "$file" ]; then
        echo "警告: ファイルが見つかりません。スキップします: $file" >&2
        continue
    fi

    if [ $(wc -l < "$file") -lt 2 ]; then
        echo "警告: ファイルの行数が2行未満です。スキップします: $file" >&2
        continue
    fi

    # awkを使用してCSVをフィルタリングおよび再構成
    awk -v col="${COLUMN}" \
        -v patterns="${MATCH_STRINGS}" \
        -v listfile="${LIST_FILE}" \
    '
    BEGIN {
        FPAT = "(\"[^\"]*\")|([^,]+)"
        OFS = ","

        # 抽出条件を match_targets 連想配列に格納する
        # -f オプションでリストファイルが指定された場合
        if (listfile != "") {
            while ((getline line < listfile) > 0) {
                # 行の前後の空白を削除
                gsub(/^[ \t]+|[ \t]+$/, "", line)
                # 空行はスキップ
                if (line == "") continue
                match_targets[line] = 1
            }
            close(listfile)
        }
        # -s オプションで文字列が指定された場合
        else if (patterns != "") {
            split(patterns, pattern_array, ",")
            for (p in pattern_array) {
                match_targets[pattern_array[p]] = 1
            }
        }
    }

    # 全ての行を配列に格納
    { lines[FNR] = $0 }

    END {
        # --- TOP/ENDレコードの形式を検証 ---
        $0 = lines[1]
        field2_top = $2
        gsub(/^"|"$/, "", field2_top)
        if (field2_top != "TOP") {
            print "エラー: 1行目がTOPレコードではありません。ファイル:", FILENAME > "/dev/stderr"
            exit 1
        }

        $0 = lines[FNR]
        field2_end = $2
        gsub(/^"|"$/, "", field2_end)
        if (field2_end != "END") {
            print "エラー: 最終行がENDレコードではありません。ファイル:", FILENAME > "/dev/stderr"
            exit 1
        }

        # 1. TOPレコードはそのまま出力
        print lines[1]

        # 2. データ行 (2行目から最終-1行目) をフィルタリング
        data_counter = 0
        if (FNR > 2) {
            for (i = 2; i < FNR; i++) {
                $0 = lines[i]

                field_to_check = $col
                gsub(/^"|"$/, "", field_to_check)

                if (field_to_check in match_targets) {
                    data_counter++
                    $1 = "\"" data_counter "\""
                    print
                }
            }
        }

        # 3. 新しいENDレコードを生成して出力
        total_records = 1 + data_counter + 1
        end_counter = total_records - 1
        
        printf "\"%d\",\"END\",\"%d\"\n", end_counter, total_records
    }
    ' "$file"
done













主な変更点
-f <リストファイル> オプションの追加

シェルスクリプトのオプション解析部分を変更し、-f オプションを受け取れるようにしました。

-s と -f は同時に指定できず、どちらか一方が必須となるように入力チェックを追加しました。

awkでのリストファイル読み込み

awkスクリプトのBEGINブロックを修正しました。

-fオプションでファイル名が渡された場合、getline関数を使ってそのファイルを1行ずつ読み込み、抽出条件のリスト（match_targets配列）を作成します。

ファイル内の各行について、前後の余計なスペースは自動で削除され、空行は無視されます。

-sオプションが使われた場合は、これまで通りカンマ区切りの文字列を解析します。

その他のロジック（TOP/ENDレコードの処理、カウンタ再附番など）は前回の改良版から引き継いでいます。

新しい使い方
元のデータ (data.csv)

コード スニペット

"0","TOP","",""
"1","DATA","G111",""
"2","DATA","G222",""
"3","DATA","G111",""
"4","DATA","G333",""
"5","END","6"
抽出条件リストファイル (filter_list.txt)
抽出したいIDを記述します。空行や重複があっても問題ありません。

Plaintext

G111

G333
G111

実行例:
-fオプションで上記filter_list.txtを指定して、3列目をフィルタリングします。

Bash

./filter_csv.sh -c 3 -f filter_list.txt data.csv
実行結果:
filter_list.txtに記載のG111とG333に一致する行が抽出され、カウンタとENDレコードが正しく更新されます。

コード スニペット

"0","TOP","",""
"1","DATA","G111",""
"2","DATA","G111",""
"3","DATA","G333",""
"4","END","5"
これで、より柔軟に抽出条件を指定できるようになったかと思います。ぜひお試しください。
